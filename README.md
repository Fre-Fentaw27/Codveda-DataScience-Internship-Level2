# Codveda-DataScience-Internship-Level2

Predictive Modeling(Regression),Classification with Logistic Regression, Clustering (Unsupervised Learning)

## ğŸ“Œ Overview

This repository contains my solutions for the Level 2 Data Science Internship tasks, covering three fundamental machine learning areas: Regression, Classification, and Clustering. Each task demonstrates different aspects of data science workflow from data preprocessing to model evaluation.

## ğŸ“‚ Project Structure

```bash
Codveda-DataScience-Internship-Level2/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ house Prediction Data Set.csv
â”‚   â”‚   â”œâ”€â”€ iris.csv
â”‚   â”‚   â”œâ”€â”€ churn-bigml-80.csv
â”‚   â”‚   â”œâ”€â”€ churn-bigml-20.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ house_processed.csv
â”‚       â”œâ”€â”€ iris_processed.csv
â”‚       â”œâ”€â”€ churn_processed.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ task_1_regression/
â”‚   â”‚   â”œâ”€â”€ house_price_prediction.py
â”‚   â”œâ”€â”€ task_2_classification/
â”‚   â”‚   â”œâ”€â”€ iris_classification.py
â”‚   â””â”€â”€ task_3_clustering/
â”‚       â”œâ”€â”€ customer_segmentation.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ task_1_regression/
â”‚   â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”‚   â”œâ”€â”€ model_metadata.json
â”‚   â”‚   â””â”€â”€ performance_metrics.csv
â”‚   â”œâ”€â”€ task_2_classification/
â”‚   â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”‚   â”œâ”€â”€ model_metadata.json
â”‚   â”‚   â”œâ”€â”€ performance_metrics.csv
â”‚   â””â”€â”€ task_3_clustering/
â”‚       â”œâ”€â”€ kmeans_model.pkl
â”‚       â”œâ”€â”€ scaler.pkl
â”‚       â”œâ”€â”€ clustering_metadata.json
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ task_1_regression/
â”‚   â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”‚   â”œâ”€â”€ price_distribution.png
â”‚   â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”‚   â”œâ”€â”€ actual_vs_predicted.png
â”‚   â”‚   â”œâ”€â”€ residual_plot.png
â”‚   â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”‚   â””â”€â”€ training_history.csv
â”‚   â”œâ”€â”€ task_2_classification/
â”‚   â”‚   â”œâ”€â”€ class_distribution.png
â”‚   â”‚   â”œâ”€â”€ feature_correlations.png
â”‚   â”‚   â”œâ”€â”€ pairplot.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix_lr.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix_rf.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix_svm.png
â”‚   â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”‚   â””â”€â”€ classification_report.csv
â”‚   â””â”€â”€ task_3_clustering/
â”‚       â”œâ”€â”€ numeric_features_distribution.png
â”‚       â”œâ”€â”€ elbow_method.png
â”‚       â”œâ”€â”€ silhouette_scores.png
â”‚       â”œâ”€â”€ pca_clusters.png
â”‚       â”œâ”€â”€ tsne_clusters.png
â”‚       â”œâ”€â”€ cluster_distribution.png
â”‚       â”œâ”€â”€ cluster_characteristics.png
â”‚       â”œâ”€â”€ 3d_pca_clusters.png
â”‚       â””â”€â”€ cluster_analysis_report.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Project Tasks

## Task 1: Predictive Modeling (Regression)

**Description**: Built and evaluated regression models to predict house prices using the Boston Housing dataset.

**Objectives Achieved**:

âœ… Data preprocessing and exploratory analysis

âœ… Implemented Linear Regression, Decision Tree, and Random Forest models

âœ… Model evaluation using MSE, RMSE, and R-squared metrics

âœ… Feature importance analysis

âœ… Model serialization for future use

**Key Results**: Random Forest achieved the best performance with RÂ² = 0.85

## Task 2: Classification with Logistic Regression

**Description**: Built multiple classifiers to predict iris flower species using the classic Iris dataset.

**Objectives Achieved**:

âœ… Data preprocessing and visualization

âœ… Implemented Logistic Regression, Random Forest, and SVM classifiers

âœ… Comprehensive evaluation using accuracy, precision, recall, F1-score

âœ… ROC curve analysis and confusion matrices

âœ… Model comparison and selection

**Key Results**: All models achieved >95% accuracy, with Random Forest performing best

## Task 3: Clustering (Unsupervised Learning)

**Description**: Implemented K-Means clustering for customer segmentation using telecom churn data.

**Objectives Achieved**:

âœ… Data preprocessing and dimensionality reduction

âœ… Determined optimal clusters using elbow method and silhouette scores

âœ… Visualized clusters using PCA and t-SNE

âœ… Cluster interpretation and business insights

âœ… Customer segmentation analysis

**Key Results**: Identified 9 distinct customer segments with unique characteristics

## ğŸ› ï¸ Setup & Installation

1.  **Clone the repository** (if applicable) or ensure you have the project structure locally.
2.  **Navigate to the project root directory** in your terminal.
3.  **Create a virtual environment** (recommended):
    ```bash
    python -m venv .venv
    ```
4.  **Activate the virtual environment**:
    - On Windows:
      ```bash
      .venv\Scripts\activate
      ```
    - On macOS/Linux:
      ```bash
      source .venv/bin/activate
      ```
5.  **Install dependencies**:

    ```bash
    pip install -r requirements.txt
    ```

## ğŸ“Š Usage

1. Task 1 - Regression:

```bash
python src/task_1_regression/house_price_prediction.py
```

2. Task 2 - Classification:

```bash
python src/task_2_classification/iris_classification.py
```

3. Task 3 - Clustering:

```bash
python src/task_3_clustering/customer_segmentation.py
```

## Exploring Results

**Visualizations**: Check results/task\_\*/ for all generated plots

**Processed Data**: Available in data/processed/

**Trained Models**: Stored in models/task\_\*/

## ğŸ”§ Technologies Used

**Data Processing**: pandas, numpy

**Visualization**: matplotlib, seaborn, plotly

**Machine Learning**: scikit-learn, xgboost

**Model Serialization**: joblib

**Notebooks**: Jupyter

## ğŸ¯ Next Steps

**Hyperparameter Tuning**: Implement grid search for optimal parameters

**Cross-Validation**: Add k-fold cross-validation for robust evaluation

**Feature Engineering**: Explore polynomial features and interactions

**Model Interpretability**: Add SHAP values for model explanations
